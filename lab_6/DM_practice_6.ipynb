{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Лабораторна робота 6: Пошук аномалій та вирішення задачі *anomaly detection* за допомогою бібліотек `scikit-learn`та `PyTorch`**\n",
    "**Всі завдання виконуються індивідуально. Використання запозиченого коду буде оцінюватись в 0 балів.**\n",
    "\n",
    "**Лабораторні роботи де в коді буде використаня КИРИЛИЦІ будуть оцінюватись в 20 балів.**"
   ],
   "metadata": {
    "id": "1i8adKFQS7E-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Мета роботи:\n",
    "Ознайомитися з основними методами виявлення аномалій, навчитися використовувати бібліотеки `scikit-learn` та `PyTorch` для реалізації алгоритмів пошуку аномалій, проаналізувати ефективність різних методів на реальних наборах даних з Kaggle.\n",
    "\n",
    "\n",
    "### Опис завдання:\n",
    "\n",
    "1. **Постановка задачі**:\n",
    "   Використовуючи один із доступних наборів даних Kaggle (наприклад, *Credit Card Fraud Detection*, *Network Intrusion*, або інші), вам потрібно розв'язати задачу виявлення аномалій. Основна мета — ідентифікувати аномальні записи серед нормальних. Вибраний набір даних повинен містити мітки аномалій для перевірки результатів.\n",
    "\n",
    "2. **Етапи виконання завдання**:\n",
    "   - Завантажте та підготуйте набір даних.\n",
    "   - Проведіть попередню обробку даних (масштабування, заповнення пропущених значень, видалення нерелевантних ознак).\n",
    "   - Використайте різні методи виявлення аномалій:\n",
    "     - **Методи з бібліотеки scikit-learn**:\n",
    "       - Isolation Forest\n",
    "       - One-Class SVM\n",
    "       - Local Outlier Factor (LOF)\n",
    "     - **Методи з використанням PyTorch**:\n",
    "       - Автоенкодери для виявлення аномалій.\n",
    "   - Порівняйте отримані результати, обчисліть метрики якості (Precision, Recall, F1-Score).\n",
    "   - Оцініть, який метод найкраще підходить для вирішення задачі на вашому наборі даних.\n",
    "\n",
    "### Покрокова інструкція\n",
    "\n",
    "1. **Підготовка середовища**:\n",
    "   - Встановіть необхідні бібліотеки:\n",
    "     ```\n",
    "     pip install scikit-learn torch pandas numpy matplotlib\n",
    "     ```\n",
    "\n",
    "2. **Вибір набору даних з Kaggle**:\n",
    "   Зареєструйтесь на Kaggle та оберіть один із наборів даних для виявлення аномалій. Наприклад:\n",
    "   - [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n",
    "   - [Network Intrusion Detection](https://www.kaggle.com/xyuanh/benchmarking-datasets)\n",
    "\n",
    "3. **Попередня обробка даних**:\n",
    "   - Завантажте дані та проведіть їхню початкову обробку.\n",
    "   - Масштабуйте ознаки за допомогою `StandardScaler` або `MinMaxScaler`.\n",
    "   - Розділіть дані на навчальну і тестову вибірки.\n",
    "\n",
    "4. **Методи з бібліотеки `scikit-learn`**:\n",
    "\n",
    "   - **Isolation Forest**:\n",
    "     ```\n",
    "     from sklearn.ensemble import IsolationForest\n",
    "     ```\n",
    "\n",
    "   - **One-Class SVM**:\n",
    "     ```\n",
    "     from sklearn.svm import OneClassSVM\n",
    "     ```\n",
    "\n",
    "   - **Local Outlier Factor**:\n",
    "     ```\n",
    "     from sklearn.neighbors import LocalOutlierFactor\n",
    "     ```\n",
    "\n",
    "5. **Методи на основі нейронних мереж (PyTorch)**:\n",
    "\n",
    "   Використайте автоенкодер для пошуку аномалій. Побудуйте нейронну мережу з енкодером і декодером. Під час навчання порівняйте відновлені дані з вхідними та обчисліть помилку. Записи з великою помилкою можуть бути аномаліями.\n",
    "\n",
    "   - **Реалізація автоенкодера**:\n",
    "     ```\n",
    "     import torch\n",
    "     import torch.nn as nn\n",
    "     import torch.optim as optim\n",
    "     ```\n",
    "\n",
    "6. **Оцінка результатів**:\n",
    "   Використовуйте метрики оцінки якості:\n",
    "   - `Precision`, `Recall`, `F1-score`\n",
    "   ```\n",
    "   from sklearn.metrics import classification_report\n",
    "   ```\n",
    "\n",
    "7. **Звіт**:\n",
    "   - Поясніть, який метод дав найкращі результати.\n",
    "   - Проаналізуйте, чому деякі методи працюють краще на вашому наборі даних.\n",
    "   - Оцініть можливості використання глибоких нейронних мереж (автоенкодерів) для вирішення задачі.\n",
    "\n",
    "\n",
    "### Результати, які необхідно надати:\n",
    "1. Код рішення у вигляді Jupyter Notebook з аналізом результатів та поясненнями.\n",
    "\n",
    "\n",
    "### Дедлайн:\n",
    "[23 жовтня 23:59]\n",
    "\n",
    "\n",
    "### Корисні ресурси:\n",
    "- [Документація PyTorch](https://pytorch.org/docs/stable/index.html)\n",
    "- [Документація scikit-learn](https://scikit-learn.org/stable/documentation.html)\n",
    "- [Kaggle Datasets](https://www.kaggle.com/datasets)"
   ],
   "metadata": {
    "id": "YvneQUbQRRqZ"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1,
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T11:44:52.528102Z",
     "start_time": "2024-10-15T11:44:52.513243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data.isnull().sum()\n",
    "print(data['Class'].value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T11:44:52.976546Z",
     "start_time": "2024-10-15T11:44:52.529386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sns.countplot(x='Class', data=data)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T11:44:53.130718Z",
     "start_time": "2024-10-15T11:44:52.977972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "robust_scaler = RobustScaler()\n",
    "\n",
    "data['scaled_amount'] = robust_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data['scaled_time'] = robust_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "\n",
    "data.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "\n",
    "scaled_amount = data['scaled_amount']\n",
    "scaled_time = data['scaled_time']\n",
    "data.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "data.insert(0, 'scaled_amount', scaled_amount)\n",
    "data.insert(1, 'scaled_time', scaled_time)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T11:44:53.352704Z",
     "start_time": "2024-10-15T11:44:53.132727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f'Training data shape: {X_train.shape}')\n",
    "print(f'Testing data shape: {X_test.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (227845, 30)\n",
      "Testing data shape: (56962, 30)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T11:44:55.328775Z",
     "start_time": "2024-10-15T11:44:53.353693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "isolation_forest = IsolationForest(n_estimators=100, max_samples='auto',\n",
    "                                   contamination=float(len(y_train[y_train == 1])) / len(y_train),\n",
    "                                   random_state=42)\n",
    "\n",
    "isolation_forest.fit(X_train)\n",
    "\n",
    "y_pred_train = isolation_forest.predict(X_train)\n",
    "y_pred_test = isolation_forest.predict(X_test)\n",
    "\n",
    "y_pred_test = [1 if x == -1 else 0 for x in y_pred_test]\n",
    "\n",
    "print(\"Isolation Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.30      0.34      0.32        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.65      0.67      0.66     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T11:50:35.861738Z",
     "start_time": "2024-10-15T11:44:55.331109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oneclass_svm = OneClassSVM(kernel='rbf', gamma=0.001, nu=0.05)\n",
    "\n",
    "X_train_norm = X_train[y_train == 0]\n",
    "oneclass_svm.fit(X_train_norm)\n",
    "\n",
    "y_pred_test = oneclass_svm.predict(X_test)\n",
    "\n",
    "y_pred_test = [1 if x == -1 else 0 for x in y_pred_test]\n",
    "\n",
    "print(\"One-Class SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Class SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     56864\n",
      "           1       0.03      0.89      0.06        98\n",
      "\n",
      "    accuracy                           0.95     56962\n",
      "   macro avg       0.51      0.92      0.51     56962\n",
      "weighted avg       1.00      0.95      0.97     56962\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T11:59:35.230349Z",
     "start_time": "2024-10-15T11:59:05.966840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=float(len(y_train[y_train == 1])) / len(y_train))\n",
    "\n",
    "y_pred_train = lof.fit_predict(X_train)\n",
    "y_pred_test = lof.fit_predict(X_test)\n",
    "\n",
    "y_pred_test = [1 if x == -1 else 0 for x in y_pred_test]\n",
    "\n",
    "print(\"Local Outlier Factor Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Outlier Factor Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.02      0.02      0.02        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.51      0.51      0.51     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T11:51:04.947341Z",
     "start_time": "2024-10-15T11:51:01.743456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_ae = X_train[y_train == 0].values \n",
    "X_test_ae = X_test.values\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_ae, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_ae, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 14),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(14, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(7, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(7, 14),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(14, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = Autoencoder(input_dim)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T11:51:33.617412Z",
     "start_time": "2024-10-15T11:51:04.948901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        inputs = data[0]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.6f}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.303331\n",
      "Epoch [2/20], Loss: 1.231916\n",
      "Epoch [3/20], Loss: 1.223227\n",
      "Epoch [4/20], Loss: 1.219853\n",
      "Epoch [5/20], Loss: 1.217573\n",
      "Epoch [6/20], Loss: 1.215810\n",
      "Epoch [7/20], Loss: 1.214236\n",
      "Epoch [8/20], Loss: 1.212736\n",
      "Epoch [9/20], Loss: 1.211432\n",
      "Epoch [10/20], Loss: 1.210307\n",
      "Epoch [11/20], Loss: 1.209422\n",
      "Epoch [12/20], Loss: 1.208747\n",
      "Epoch [13/20], Loss: 1.208511\n",
      "Epoch [14/20], Loss: 1.208103\n",
      "Epoch [15/20], Loss: 1.207813\n",
      "Epoch [16/20], Loss: 1.207619\n",
      "Epoch [17/20], Loss: 1.207393\n",
      "Epoch [18/20], Loss: 1.207159\n",
      "Epoch [19/20], Loss: 1.206998\n",
      "Epoch [20/20], Loss: 1.206896\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T11:53:06.968084Z",
     "start_time": "2024-10-15T11:53:06.734249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs = data[0]\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        errors.extend(torch.mean((outputs - inputs) ** 2, dim=1).numpy())\n",
    "\n",
    "errors = np.array(errors)\n",
    "threshold = np.percentile(errors, 95) \n",
    "y_pred_ae = (errors > threshold).astype(int)\n",
    "\n",
    "print(\"Autoencoder Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_ae))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     56864\n",
      "           1       0.03      0.87      0.06        98\n",
      "\n",
      "    accuracy                           0.95     56962\n",
      "   macro avg       0.51      0.91      0.52     56962\n",
      "weighted avg       1.00      0.95      0.97     56962\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Висновки:\n",
    "Для нашого набору даних найефективнішим виявився метод Isolation Forest. Він показав високу точність і хороші показники Precision, Recall та F1-score у виявленні шахрайських транзакцій. Він також ефективно ізолював аномальні спостереження через свою здатність будувати випадкові дерева ізоляції і стійкість до великої кількості даних , а також не вимагає припущень щодо розподілу даних.\n",
    "\n",
    "Аналіз роботи методів на датасеті - Credit Card Fraud Detection:\n",
    "\n",
    "    1. Isolation Forest працює ефективно на великих наборах даних з дисбалансом класів, оскільки він випадковим чином підрозділяє дані, ізолюючи аномалії, які потребують меншої кількості підрозділів для ізоляції.\n",
    "    2. One-Class SVM показав меншу продуктивність, через те що має чутливістю до розміру даних та дисбалансу класів. Великі обсяги даних ускладнюють побудову гіперплощини, яка ефективно розділяє нормальні дані від аномалій, а через дисбаланс класів вона перенавчається на нормальних даних.\n",
    "    3. Local Outlier Factor (LOF) не зміг ефективно знайти аномалії. Можливо через те, що LOF є біляше для локальної щільності даних. У випадку шахрайських транзакцій, аномалії можуть не утворювати щільні локальні кластери, що ускладнює їх виявлення цим методом.\n",
    "Оцінка можливостей використання автоенкодерів:\n",
    "\n",
    "    1. Автоенкодер, реалізований за допомогою PyTorch, показав досить непогані результати, а також хорошу здатність виявляти аномалії на основі помилки реконструкції. Модель навчилася відтворювати патерни нормальних транзакцій, а будь-які значні відхилення коли була реконструкція вказувала про можливі аномалії.\n",
    "    \n",
    "    2. Автоекодери є дуже корисним у датасетах з великою кількістю даних з прихованими патернами, характерними для аномалій через те, що можуть захоплювати складні нелінійні взаємозв'язки між ознаками\n",
    "    \n",
    "    3. Їх використання є хорошим варіантом для задач виявлення аномалій, особливо коли у нас великий обсяг даних для навчання. Але також потрібно враховувати, що нам потрібно використовувати вельку кількість обчислювальних ресурсів, а також ретельноЇ настройки гіперпараметрів для нашої моделі, щоб отримати оптимальних результатів.\n"
   ]
  }
 ]
}
